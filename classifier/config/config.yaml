server:
  host: "0.0.0.0"
  port: 8000
  workers: 4
  threads: 4
  timeout: 120
  keep_alive: 10
  max_requests: 1000
  max_requests_jitter: 50
  worker_connections: 1000
  backlog: 2048
  log_level: "INFO"
  preload_app: true

model:
  save_dir: "/app/train"
  instances: 1
  max_length: 512
  batch_size: 32
  name: "distilbert-base-uncased"

weights:
  quality: 0.8
  cost: 0.2

model_scores:
  models:

# PRO

    gemini-2.5-flash-preview: # reasoning & translation
      provider: "gemini"
      provider_model_name: "gemini-2.5-flash-preview-04-17"
      display_name: "Gemini 2.5 Flash Preview"
      tier: "pro"
      cost_per_request: 0.1
      is_default: false
      is_thinking_model: false
      conversation: 0.980
      classification: 0.950
      roleplay: 0.970
      data_analysis: 0.970
      translation: 2.00
      problem_solving: 0.990
      reasoning: 2.00
      code_generation: 0.970
      writing: 0.970
      summarization: 0.960
      math: 0.990
      creative: 0.970
      research: 0.980
      extraction: 0.960

    gemini-2.5-pro-preview: # code generation
      provider: "gemini"
      provider_model_name: "gemini-2.5-pro-preview-06-05"
      display_name: "Gemini 2.5 Pro Preview"
      tier: "pro"
      cost_per_request: 0.1
      is_default: false
      is_thinking_model: true
      conversation: 0.1
      classification: 0.1
      roleplay: 0.1
      data_analysis: 0.1
      translation: 0.1
      problem_solving: 0.990
      reasoning: 0.990
      code_generation: 2.00
      writing: 0.1
      summarization: 0.1
      math: 0.99
      creative: 0.1
      research: 0.980
      extraction: 0.1

    gemini-2.0-flash: # conversation
      provider: "gemini"
      provider_model_name: "gemini-2.0-flash"
      display_name: "Gemini 2.0 Flash"
      tier: "pro"
      cost_per_request: 0.1
      is_default: true
      is_thinking_model: false
      conversation: 2.00
      classification: 0.910
      roleplay: 0.960
      data_analysis: 0.950
      translation: 0.900
      problem_solving: 0.970
      reasoning: 0.980
      code_generation: 0.960
      writing: 0.940
      summarization: 0.920
      math: 0.980
      creative: 0.940
      research: 0.950
      extraction: 0.920

    gemini-2.0-flash-lite: # summarization
      provider: "gemini"
      provider_model_name: "gemini-2.0-flash-lite"
      display_name: "Gemini 2.0 Flash Lite"
      tier: "pro"
      cost_per_request: 0.1
      is_default: false
      is_thinking_model: false
      conversation: 0.950
      classification: 0.880
      roleplay: 0.950
      data_analysis: 0.940
      translation: 0.880
      problem_solving: 0.970
      reasoning: 0.980
      code_generation: 0.960
      writing: 0.940
      summarization: 2.00
      math: 0.980
      creative: 0.940
      research: 0.950
      extraction: 0.910

    gemini-1.5-pro:
      provider: "gemini"
      provider_model_name: "gemini-1.5-pro"
      display_name: "Gemini 1.5 Pro"
      tier: "pro"
      cost_per_request: 0.1
      is_default: false
      is_thinking_model: false
      conversation: 0.960
      classification: 0.910
      roleplay: 0.960
      data_analysis: 0.930
      translation: 0.880
      problem_solving: 0.950
      reasoning: 0.970
      code_generation: 0.940
      writing: 0.930
      summarization: 0.910
      math: 0.950
      creative: 0.920
      research: 0.940
      extraction: 0.900

# FREE

    # kimi-dev-72b:
    #   provider: "openrouter"
    #   provider_model_name: "moonshotai/kimi-dev-72b:free"
    #   display_name: "Kimi Dev 72B"
    #   tier: "free"
    #   cost_per_request: 0.0
    #   is_default: false
    #   is_thinking_model: true
    #   conversation: 0.930
    #   classification: 0.880
    #   roleplay: 0.900
    #   data_analysis: 0.890
    #   translation: 0.930
    #   problem_solving: 0.920
    #   reasoning: 0.900
    #   code_generation: 0.940
    #   writing: 0.5
    #   summarization: 0.900
    #   math: 0.890
    #   creative: 0.890
    #   research: 0.900
    #   extraction: 0.900

    gemma2-9b-it:
      provider: "groq"
      provider_model_name: "gemma2-9b-it"
      display_name: "Gemma 2 9B"
      tier: "free"
      cost_per_request: 0.0
      is_default: false
      is_thinking_model: false
      conversation: 0.930
      classification: 0.880
      roleplay: 0.900
      data_analysis: 0.890
      translation: 0.930
      problem_solving: 0.920
      reasoning: 0.900
      code_generation: 0.940
      writing: 2.00
      summarization: 0.900
      math: 0.890
      creative: 0.890
      research: 0.900
      extraction: 0.900

    llama-3.3-70b-versatile: # problem_solving
      provider: "groq"
      provider_model_name: "llama-3.3-70b-versatile"
      display_name: "Llama 3.3 70B Versatile"
      tier: "free"
      cost_per_request: 0.0
      is_default: false
      is_thinking_model: false
      conversation: 0.920
      classification: 0.890
      roleplay: 0.910
      data_analysis: 0.880
      translation: 0.930
      problem_solving: 2.00
      reasoning: 0.910
      code_generation: 0.940
      writing: 0.900
      summarization: 0.910
      math: 0.890
      creative: 0.890
      research: 0.880
      extraction: 0.880

    qwen-qwen3-32b: # conversation
      provider: "groq"
      provider_model_name: "qwen/qwen3-32b"
      display_name: "Qwen 3 32B"
      tier: "free"
      cost_per_request: 0.0
      is_default: false
      is_thinking_model: true
      conversation: 0.93
      classification: 0.92
      roleplay: 0.92
      data_analysis: 0.93
      translation: 0.92
      problem_solving: 0.98
      reasoning: 0.99
      code_generation: 2.00
      writing: 0.93
      summarization: 0.92
      math: 0.98
      creative: 0.93
      research: 0.94
      extraction: 0.92

    deepseek-deepseek-r1-0528-qwen3-8b:
      provider: "openrouter"
      provider_model_name: "deepseek/deepseek-r1-0528-qwen3-8b:free"
      display_name: "DeepSeek R1 Qwen3"
      tier: "free"
      cost_per_request: 0.0
      is_default: false
      is_thinking_model: true
      conversation: 0.00
      classification: 0.00
      roleplay: 0.00
      data_analysis: 0.00
      translation: 0.95
      problem_solving: 1.00
      reasoning: 2.00
      code_generation: 5.00
      writing: 1.50
      summarization: 0.95
      math: 1.00
      creative: 0.96
      research: 0.97
      extraction: 0.95

    deepseek-deepseek-r1-0528:
      provider: "openrouter"
      provider_model_name: "deepseek/deepseek-r1-0528:free"
      display_name: "DeepSeek R1"
      tier: "free"
      cost_per_request: 0.0
      is_default: false
      is_thinking_model: true
      conversation: 0.00
      classification: 0.0
      roleplay: 0.0
      data_analysis: 0.0
      translation: 0.90
      problem_solving: 0.96
      reasoning: 0.97
      code_generation: 0.94
      writing: 0.91
      summarization: 0.90
      math: 0.96
      creative: 0.91
      research: 0.92
      extraction: 0.90

    # llama-3.3-nemotron-super: # summarization
    #   provider: "openrouter"
    #   provider_model_name: "nvidia/llama-3.3-nemotron-super-49b-v1:free"
    #   display_name: "Llama 3.3 Nemotron Super 49B"
    #   tier: "free"
    #   cost_per_request: 0.0
    #   is_default: false
    #   is_thinking_model: false
    #   conversation: 0.940
    #   classification: 0.900
    #   roleplay: 0.920
    #   data_analysis: 0.920
    #   translation: 0.930
    #   problem_solving: 0.930
    #   reasoning: 0.940
    #   code_generation: 0.950
    #   writing: 0.930
    #   summarization: 2.00
    #   math: 0.940
    #   creative: 0.920
    #   research: 0.920
    #   extraction: 0.900

    # qwen-qwen3-235b-a22b: # code generation & reasoning
    #   provider: "openrouter"
    #   provider_model_name: "qwen/qwen3-235b-a22b:free"
    #   display_name: "Qwen 3 235B"
    #   tier: "free"
    #   cost_per_request: 0.0
    #   is_default: false
    #   is_thinking_model: true
    #   conversation: 0.00
    #   classification: 0.00
    #   roleplay: 0.00
    #   data_analysis: 0.00
    #   translation: 0.95
    #   problem_solving: 1.00
    #   reasoning: 2.00
    #   code_generation: 5.00
    #   writing: 0.96
    #   summarization: 0.95
    #   math: 1.00
    #   creative: 0.96
    #   research: 0.97
    #   extraction: 0.95





    # llama-4-maverick: # conversation
    #   provider: "openrouter"
    #   provider_model_name: "meta-llama/llama-4-maverick:free"
    #   display_name: "Llama 4 Maverick"
    #   tier: "free"
    #   cost_per_request: 0.0
    #   is_default: false
    #   is_thinking_model: false
    #   conversation: 2.00
    #   classification: 0.860
    #   roleplay: 0.880
    #   data_analysis: 0.840
    #   translation: 0.900
    #   problem_solving: 0.870
    #   reasoning: 0.880
    #   code_generation: 0.920
    #   writing: 0.870
    #   summarization: 0.880
    #   math: 0.860
    #   creative: 0.870
    #   research: 0.850
    #   extraction: 0.870

    # llama-4-scout:
    #   provider: "openrouter"
    #   provider_model_name: "meta-llama/llama-4-scout:free"
    #   display_name: "Llama 4 Scout"
    #   tier: "free"
    #   cost_per_request: 0.0
    #   is_default: false
    #   is_thinking_model: false
    #   conversation: 0.00
    #   classification: 0.850
    #   roleplay: 0.870
    #   data_analysis: 0.840
    #   translation: 0.900
    #   problem_solving: 0.870
    #   reasoning: 0.880
    #   code_generation: 0.910
    #   writing: 0.870
    #   summarization: 0.880
    #   math: 0.860
    #   creative: 0.870
    #   research: 0.850
    #   extraction: 0.860

    # llama3-70b-8192: # conversation & writing
    #   provider: "groq"
    #   provider_model_name: "llama3-70b-8192"
    #   display_name: "Llama 3 70B"
    #   tier: "free"
    #   cost_per_request: 0.0
    #   is_default: true
    #   is_thinking_model: false
    #   conversation: 2.00
    #   classification: 0.880
    #   roleplay: 0.900
    #   data_analysis: 0.870
    #   translation: 0.920
    #   problem_solving: 0.890
    #   reasoning: 0.900
    #   code_generation: 0.930
    #   writing: 0.890
    #   summarization: 0.900
    #   math: 0.880
    #   creative: 0.880
    #   research: 0.870
    #   extraction: 0.870



    # gemini-1.5-flash:
    #   provider: "gemini"
    #   provider_model_name: "gemini-1.5-flash"
    #   display_name: "Gemini 1.5 Flash"
    #   tier: "pro"
    #   cost_per_request: 0.008
    #   is_default: false
    #   is_thinking_model: false
    #   conversation: 0.920
    #   classification: 0.890
    #   roleplay: 0.910
    #   data_analysis: 0.900
    #   translation: 0.850
    #   problem_solving: 0.930
    #   reasoning: 0.950
    #   code_generation: 0.880
    #   writing: 0.870
    #   summarization: 0.880
    #   math: 0.950
    #   creative: 0.870
    #   research: 0.880
    #   extraction: 0.860

    # llama-3.1-8b:
    #   provider: "groq"
    #   provider_model_name: "llama-3.1-8b-instant"
    #   display_name: "Llama 3.1 8B"
    #   tier: "free"
    #   cost_per_request: 0.0
    #   is_default: true
    #   is_thinking_model: false
    #   conversation: 0.890
    #   classification: 0.860
    #   roleplay: 0.880
    #   data_analysis: 0.840
    #   translation: 0.900
    #   problem_solving: 0.870
    #   reasoning: 0.880
    #   code_generation: 0.950
    #   writing: 0.870
    #   summarization: 0.880
    #   math: 0.860
    #   creative: 0.870
    #   research: 0.850
    #   extraction: 0.860

    # llama3-8b-8192:
    #   provider: "groq"
    #   provider_model_name: "llama3-8b-8192"
    #   display_name: "Llama 3 8B"
    #   tier: "free"
    #   cost_per_request: 0.0
    #   is_default: false
    #   is_thinking_model: false
    #   conversation: 0.870
    #   classification: 0.840
    #   roleplay: 0.860
    #   data_analysis: 0.820
    #   translation: 0.880
    #   problem_solving: 0.850
    #   reasoning: 0.860
    #   code_generation: 0.900
    #   writing: 0.850
    #   summarization: 0.860
    #   math: 0.840
    #   creative: 0.850
    #   research: 0.830
    #   extraction: 0.840

    # qwen-qwq-32b:
    #   provider: "groq"
    #   provider_model_name: "qwen-qwq-32b"
    #   display_name: "Qwen QWQ 32B"
    #   tier: "free"
    #   cost_per_request: 0.0
    #   is_default: false
    #   is_thinking_model: true
    #   conversation: 0.92
    #   classification: 0.91
    #   roleplay: 0.91
    #   data_analysis: 0.92
    #   translation: 0.91
    #   problem_solving: 0.97
    #   reasoning: 0.98
    #   code_generation: 0.95
    #   writing: 0.92
    #   summarization: 0.91
    #   math: 0.97
    #   creative: 0.92
    #   research: 0.93
    #   extraction: 0.91

    # microsoft-phi-4-reasoning-plus:
    #   provider: "openrouter"
    #   provider_model_name: "microsoft/phi-4-reasoning-plus:free"
    #   display_name: "Phi-4 Reasoning Plus"
    #   tier: "free"
    #   cost_per_request: 0.0
    #   is_default: false
    #   is_thinking_model: true
    #   conversation: 0.92
    #   classification: 0.91
    #   roleplay: 0.91
    #   data_analysis: 0.92
    #   translation: 0.91
    #   problem_solving: 0.97
    #   reasoning: 0.98
    #   code_generation: 0.95
    #   writing: 0.92
    #   summarization: 0.91
    #   math: 0.97
    #   creative: 0.92
    #   research: 0.93
    #   extraction: 0.91

    # microsoft-phi-4-reasoning:
    #   provider: "openrouter"
    #   provider_model_name: "microsoft/phi-4-reasoning:free"
    #   display_name: "Phi-4 Reasoning"
    #   tier: "free"
    #   cost_per_request: 0.0
    #   is_default: false
    #   is_thinking_model: true
    #   conversation: 0.91
    #   classification: 0.90
    #   roleplay: 0.90
    #   data_analysis: 0.91
    #   translation: 0.90
    #   problem_solving: 0.96
    #   reasoning: 0.97
    #   code_generation: 0.94
    #   writing: 0.91
    #   summarization: 0.90
    #   math: 0.96
    #   creative: 0.91
    #   research: 0.92
      # extraction: 0.90

    # qwen-qwen3-30b-a3b:
    #   provider: "openrouter"
    #   provider_model_name: "qwen/qwen3-30b-a3b:free"
    #   display_name: "Qwen 3 30B A3B"
    #   tier: "free"
    #   cost_per_request: 0.0
    #   is_default: false
    #   is_thinking_model: true
    #   conversation: 0.93
    #   classification: 0.92
    #   roleplay: 0.92
    #   data_analysis: 0.93
    #   translation: 0.92
    #   problem_solving: 0.98
    #   reasoning: 0.99
    #   code_generation: 0.96
    #   writing: 0.93
    #   summarization: 0.92
    #   math: 0.98
    #   creative: 0.93
    #   research: 0.94
    #   extraction: 0.92

    # qwen-qwen3-14b:
    #   provider: "openrouter"
    #   provider_model_name: "qwen/qwen3-14b:free"
    #   display_name: "Qwen 3 14B"
    #   tier: "free"
    #   cost_per_request: 0.0
    #   is_default: false
    #   is_thinking_model: true
    #   conversation: 0.91
    #   classification: 0.90
    #   roleplay: 0.90
    #   data_analysis: 0.91
    #   translation: 0.90
    #   problem_solving: 0.96
    #   reasoning: 0.97
    #   code_generation: 0.94
    #   writing: 0.91
    #   summarization: 0.90
    #   math: 0.96
    #   creative: 0.91
    #   research: 0.92
    #   extraction: 0.90

    # deepseek-deepseek-v3-base:
    #   provider: "openrouter"
    #   provider_model_name: "deepseek/deepseek-v3-base:free"
    #   display_name: "DeepSeek V3 Base"
    #   tier: "free"
    #   cost_per_request: 0.0
    #   is_default: false
    #   is_thinking_model: false
    #   conversation: 0.91
    #   classification: 0.90
    #   roleplay: 0.90
    #   data_analysis: 0.91
    #   translation: 0.90
    #   problem_solving: 0.96
    #   reasoning: 0.97
    #   code_generation: 0.94
    #   writing: 0.91
    #   summarization: 0.90
    #   math: 0.96
    #   creative: 0.91
    #   research: 0.92
    #   extraction: 0.90

    # deepseek-deepseek-chat-v3-0324:
    #   provider: "openrouter"
    #   provider_model_name: "deepseek/deepseek-chat-v3-0324:free"
    #   display_name: "DeepSeek Chat V3 0324"
    #   tier: "free"
    #   cost_per_request: 0.0
    #   is_default: false
    #   is_thinking_model: false
    #   conversation: 0.92
    #   classification: 0.91
    #   roleplay: 0.91
    #   data_analysis: 0.92
    #   translation: 0.91
    #   problem_solving: 0.97
    #   reasoning: 0.98
    #   code_generation: 0.95
    #   writing: 0.92
    #   summarization: 0.91
    #   math: 0.97
    #   creative: 0.92
    #   research: 0.93
    #   extraction: 0.91

    # deepseek-deepseek-r1:
    #   provider: "openrouter"
    #   provider_model_name: "deepseek/deepseek-r1:free"
    #   display_name: "DeepSeek R1 (OpenRouter)"
    #   tier: "free"
    #   cost_per_request: 0.0
    #   is_default: false
    #   is_thinking_model: false
    #   conversation: 0.91
    #   classification: 0.90
    #   roleplay: 0.90
    #   data_analysis: 0.91
    #   translation: 0.90
    #   problem_solving: 0.96
    #   reasoning: 0.97
    #   code_generation: 0.94
    #   writing: 0.91
    #   summarization: 0.90
    #   math: 0.96
    #   creative: 0.91
    #   research: 0.92
    #   extraction: 0.90

    # deepseek-deepseek-chat:
    #   provider: "openrouter"
    #   provider_model_name: "deepseek/deepseek-chat:free"
    #   display_name: "DeepSeek Chat (OpenRouter)"
    #   tier: "free"
    #   cost_per_request: 0.0
    #   is_default: false
    #   is_thinking_model: false
    #   conversation: 0.92
    #   classification: 0.91
    #   roleplay: 0.91
    #   data_analysis: 0.92
    #   translation: 0.91
    #   problem_solving: 0.97
    #   reasoning: 0.98
    #   code_generation: 0.95
    #   writing: 0.92
    #   summarization: 0.91
    #   math: 0.97
    #   creative: 0.92
    #   research: 0.93
    #   extraction: 0.91
